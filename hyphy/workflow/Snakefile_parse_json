from os import path
import numpy as np
import pandas as pd
import os.path as path
import gzip

#with open ("updated_json.txt","r") as file:
with open("relaxJson.txt","r") as file:
    samples = [line.strip() for line in file if line.strip()]

rule all:
    input:
       parsed = expand("../pyparseRelax/{sample}.txt", sample = samples),
       outcsv = "../RELAX_xy.csv.gz"

rule json_parse:
    input:
        "../relax_XY/{sample}_relax.json"
    output:
        "../pyparseRelax/{sample}.txt"
    resources:
        tmpdir = "/ohta2/bianca.sacchi/tmp"
    script:
        "parse_jsonRelax.py"


#def list_txt_files(directory):
#    return [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.txt')]

# Directory where .txt files are located (adjust as per your directory structure)
#txt_files_directory = "../pyparseRelax"

# List of .txt files in the directory
#txt_files = list_txt_files(txt_files_directory)

rule concat:
    input: 
        expand("../pyparseRelax/{index}.txt", index=samples)
    output:
        temp("../RELAX_xy.csv")
    run:
        dfs = [pd.read_csv(file) for file in input]
        concatenated_df = pd.concat(dfs, ignore_index = True)
        concatenated_df.to_csv(output[0], index = False) 

rule gzip:
    input:
        rules.concat.output
    output:
        "../RELAX_xy.csv.gz"
    shell:
        "gzip {input}"
